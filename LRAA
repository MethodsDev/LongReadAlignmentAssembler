#!/usr/bin/env python
# encoding: utf-8

import sys, os, re
import pysam
import argparse
import subprocess
from collections import defaultdict

sys.path.insert(0, os.path.sep.join([os.path.dirname(os.path.realpath(__file__)), "pylib"]))
from Splice_graph import Splice_graph
from PASA_SALRAA import PASA_SALRAA
from Transcript import Transcript, GTF_contig_to_transcripts
from Quantify import Quantify
import Util_funcs
import PASA_SALRAA_Globals
import MultiProcessManager as mpm
import logging



#FORMAT = "%(asctime)-15s %(levelname)s %(module)s.%(name)s.%(funcName)s at %(lineno)d :\n\t%(message)s\n"
FORMAT = "%(asctime)-15s %(levelname)s %(module)s.%(name)s.%(funcName)s:\n\t%(message)s\n"

logger = logging.getLogger()
logging.basicConfig(format=FORMAT, level=logging.INFO)


#VERSION="0.0.8"
VERSION="BLEEDING_EDGE-post-v0.0.8"

def main():

    parser = argparse.ArgumentParser(description="LRAA: Long Read Alignment Assembler",
                                     formatter_class=argparse.ArgumentDefaultsHelpFormatter)

    parser.add_argument("--bam", type=str, required=True, help="target bam file")
    parser.add_argument("--genome", type=str, required=True, help="target genome file")

    parser.add_argument("--gtf", type=str, required=False, help="GTF to incorporate as guide during reconstruction or for targeting quant-only")
    
    parser.add_argument("--output_prefix", type=str, default="LRAA", help="prefix for output filenames")

    parser.add_argument("--single_best_only", action='store_true', default=False,
                        help="only report the single highest scoring isoform per component")

    parser.add_argument("--CPU", type=int, default=1,
                        help="number of cores for multithreading")


    parser.add_argument("--no_norm", action='store_true', default=False, help="do not run read coverage normalization before isoform reconstruction (equivalent to --normalize_max_cov_level 0)")
    
    parser.add_argument("--normalize_max_cov_level", type=int, default=PASA_SALRAA_Globals.config['normalize_max_cov_level'],
                        help="normalize to max read coverage level before assembly (default: {})".format(PASA_SALRAA_Globals.config['normalize_max_cov_level']))

    parser.add_argument("--quant_only", action='store_true', default=False, help="perform quantification only (must specify --gtf with targets for quant)")

    parser.add_argument("--EM", action='store_true', default=False, help="run EM alg (default: not EM, simply divide uncertain mappings equally among assigned target isoforms")

    parser.add_argument("--include_asm_draft_quant", action='store_true', default=False, help="include the draft (not real... based on norm reads) quant values at assembly. Potentially useful for isoform fraction info only")

    parser.add_argument("--version", action='store_true', default=False, help='display version: {}'.format(VERSION))
    
    ## debug params
    
    debug_group = parser.add_argument_group("debug settings")

    
    debug_group.add_argument("--debug", "-d", action='store_true', default=False,
                        help='debug mode, more verbose')

    debug_group.add_argument("--mpm_monitor", action='store_true', default=False) # multiprocessing monitor


    ## config settings

    config_group = parser.add_argument_group("config settings")

    # disabling spacers for now - important for illumina or dirty long reads
    #config_group.add_argument("--allow_spacers", action='store_true', default=False)

    config_group.add_argument("--min_path_score", type=float, default=PASA_SALRAA_Globals.config['min_path_score'],
                              help="minimum score for an isoform to be reported. default({})".format(PASA_SALRAA_Globals.config['min_path_score']))

    config_group.add_argument("--min_per_id", type=float, default=PASA_SALRAA_Globals.config['min_per_id'],
                              help='min per_id for pacbio read alignments. default: ({})'.format(PASA_SALRAA_Globals.config['min_per_id']))

    config_group.add_argument("--min_mapping_quality", type=int, default=PASA_SALRAA_Globals.config['min_mapping_quality'],
                            help="minimum read alignment mapping quality (default: {})".format(PASA_SALRAA_Globals.config['min_mapping_quality']))
    
    config_group.add_argument("--min_isoform_fraction", type=float, default=PASA_SALRAA_Globals.config['min_isoform_fraction'],
                              help='exclude reconstructed isoforms that have read support less than this fraction of all isoforms at each gene (no impact on --quant_only). default: ({})'.format(PASA_SALRAA_Globals.config['min_isoform_fraction']))

    config_group.add_argument("--no_infer_TSS", action='store_true', default=False, help='do not infer TSS')
    config_group.add_argument("--no_infer_PolyA", action='store_true', default=False, help='do not infer_PolyA')

    #config_group.add_argument("--try_correct_alignments", action='store_true', default=False, help='try to correct alignments at terminal soft clips')
    
    #config_group.add_argument("--collapse", action='store_true', default=False, help='collapse isoforms that are compatible and contained by longer isoforms')
    
    ## alt splice settings

    config_group_altsplice = parser.add_argument_group("alt splice settings")

    # TODO:// mv splice defaults to globals.config
    config_group_altsplice.add_argument("--min_alt_splice_freq", type=float, default=PASA_SALRAA_Globals.config['min_alt_splice_freq'],
                                        help="min fraction required for alt splicing at an exon boundary (default: {})".format(PASA_SALRAA_Globals.config['min_alt_splice_freq']))
    
    config_group_altsplice.add_argument("--min_alt_unspliced_freq", type=float, default=PASA_SALRAA_Globals.config['min_alt_unspliced_freq'],
                                        help="min fraction required for retained intron at splice boundary (default: {})".format(PASA_SALRAA_Globals.config['min_alt_unspliced_freq']))
    
    
    ## restrict to contig and optionally region of contig

    contig_group_setting = parser.add_argument_group("target specific contig (or region of contig)")

    contig_group_setting.add_argument("--restrict_to_contig", type=str, default=None,
                                      help="restrict run to single contig")
    contig_group_setting.add_argument("--restrict_region_range", type=str, default=None,
                                      help="restrict to region on contig lend:rend")

    


    if "--version" in sys.argv:
        print("LRAA VERSION: {}".format(VERSION))
        if len(sys.argv) == 2:
            sys.exit(0)
    
    args = parser.parse_args()
    
    genome_fasta_filename = args.genome
    bam_filename = args.bam
    output_prefix = args.output_prefix
    single_best_only = args.single_best_only
    CPU = args.CPU
    QUANT_ONLY = args.quant_only
    input_gtf = args.gtf
    NO_NORM = args.no_norm
    min_isoform_fraction = args.min_isoform_fraction
    run_EM = args.EM

    #if args.collapse:
    #    PASA_SALRAA_Globals.config['collapse_alt_TSS_and_PolyA'] = True
    
    
    if args.quant_only and input_gtf is None:
        sys.exit("If running --quant_only, must specify --gtf corresponding to targets of quantification")
    
    # update config
    PASA_SALRAA_Globals.config['min_path_score'] = args.min_path_score
    PASA_SALRAA_Globals.config['min_per_id'] = args.min_per_id
    PASA_SALRAA_Globals.config['min_mapping_quality'] = args.min_mapping_quality
    PASA_SALRAA_Globals.config['min_isoform_fraction'] = args.min_isoform_fraction
    PASA_SALRAA_Globals.config['infer_TSS'] = not args.no_infer_TSS
    PASA_SALRAA_Globals.config['infer_PolyA'] = not args.no_infer_PolyA
    #PASA_SALRAA_Globals.config['try_correct_alignments'] = args.try_correct_alignments
    
    
    if args.mpm_monitor:
        mpm.set_debug()

    
    if args.debug:
        logging.getLogger().setLevel(logging.DEBUG)
        PASA_SALRAA_Globals.DEBUG = True


    allow_spacers = False
    #allow_spacers = args.allow_spacers

    if not os.path.exists(bam_filename + ".bai"):
        logger.info("-missing index for bam {}, will try to make it...".format(bam_filename))
        subprocess.check_call("samtools index " + bam_filename, shell=True)
        
    
    ## perform normalization prior to assembly
    pre_norm_bam_filename = bam_filename

    bam_file_for_quant = pre_norm_bam_filename
    bam_file_for_sg = pre_norm_bam_filename
    
    if (not QUANT_ONLY) and (not NO_NORM) and (args.normalize_max_cov_level > 0):

        SS_bamsifter_prog = os.path.sep.join([os.path.dirname(os.path.realpath(__file__)), "util/normalize_bam_by_strand.py"])

        norm_bam_filename = os.path.basename(bam_filename) + f".norm_{args.normalize_max_cov_level}.bam"
        
        cmd = " ".join([SS_bamsifter_prog,
                        f" --input_bam {bam_filename}",
                        f" --normalize_max_cov_level {args.normalize_max_cov_level} ",
                        f" --output_bam {norm_bam_filename} " ] )
                                
        norm_bam_checkpoint = norm_bam_filename + ".ok"
        if not os.path.exists(norm_bam_checkpoint):
            logger.info("generating normalized bam file")
            logger.info(cmd)
            subprocess.check_call(cmd, shell=True)

            subprocess.check_call(f"touch {norm_bam_checkpoint}", shell=True)


        bam_file_for_sg = norm_bam_filename


    ###########################################
    ## on to isoform discovery / reconstruction 
            

    splice_graph_params_dict = { 'read_aln_gap_merge_int' :  10,
                                 'inter_exon_segment_merge_dist' : 50,
                                 'max_genomic_contig_length' : 1e10,
                                 'min_alt_splice_freq' : args.min_alt_splice_freq,
                                 'min_alt_unspliced_freq' : args.min_alt_unspliced_freq,
                                 'max_intron_length_for_exon_segment_filtering' : 10000,
                                 'min_intron_support' : 1,
                                 'min_terminal_splice_exon_anchor_length' : 15,
                                 'remove_unspliced_introns' : False }
    # TODO:// put above settings into the config and add to cmd line interface
    
    Splice_graph.init_sg_params(splice_graph_params_dict)
    
    
    # data structures want:
    # ultimately exons and introns
    # build from reads.
    # define coverage intervals and introns as graph components.

    restrict_to_contig_orient = None

    if args.restrict_to_contig:
        restricted_contig = args.restrict_to_contig
        m = re.search("^(\\w+)([\\+\\-])$", restricted_contig)
        if m is not None:
            restricted_contig = m.group(1)
            restrict_to_contig_orient = m.group(2)
        
        genome_contigs_list = [restricted_contig]
    else:
        genome_contigs_list = get_genome_contigs_listing(genome_fasta_filename)

    restrict_region_lend, restrict_region_rend = None, None
    if args.restrict_region_range:
        restrict_region_lend, restrict_region_rend = re.split("[\\:\\-]", args.restrict_region_range)
        restrict_region_lend = int(restrict_region_lend)
        restrict_region_rend = int(restrict_region_rend)
        assert restrict_region_lend < restrict_region_rend, f"Error, {args.restrict_region_range} invalid range"


    prereconstruct_info_dir = "__prereconstruct"
    if PASA_SALRAA_Globals.DEBUG: 
        if not os.path.exists(prereconstruct_info_dir):
            os.makedirs(prereconstruct_info_dir)
    
    contig_strand_to_input_transcripts = defaultdict(list)
    if input_gtf:
        logger.info(f"-capturing input transcripts from gtf {input_gtf}")
        contig_to_input_transcripts = GTF_contig_to_transcripts.parse_GTF_to_Transcripts(input_gtf)
        for contig, transcript_obj_list in contig_to_input_transcripts.items():
            for transcript in transcript_obj_list:
                transcript_strand = transcript.get_strand()
                contig_strand_token = "{}^{}".format(contig, transcript_strand)
                contig_strand_to_input_transcripts[contig_strand_token].append(transcript)
        
    ##----------------------------------------------
    ## Begin, target each contig separately

    ofh_quant_read_tracker = None
    if QUANT_ONLY:
        output_filename = f"{output_prefix}.quant.expr"
        ofh_quant_read_tracking_filename = f"{output_prefix}.quant.tracking"
        ofh_quant_read_tracker = open(ofh_quant_read_tracking_filename, "wt")
        # write header
        print("\t".join(["gene_id", "transcript_id", "read_name", "frac_assigned"]), file=ofh_quant_read_tracker)
    else:
        output_filename = f"{output_prefix}.gtf"
        
    ofh = open(output_filename, 'wt')
    if QUANT_ONLY:
        # write header
        print("\t".join(["gene_id", "transcript_id", "uniq_reads", "all_reads", "isoform_fraction", "unique_gene_read_fraction"]), file=ofh)
    
    
    for contig_acc in genome_contigs_list:

        contig_seq_str = Util_funcs.retrieve_contig_seq_from_fasta_file(contig_acc, genome_fasta_filename)
        
        for contig_strand in ('+','-'):

            if restrict_to_contig_orient is not None and restrict_to_contig_orient != contig_strand:
                continue
        
            logger.info(f"-processing contig: {contig_acc} {contig_strand}")

            ##-------------------
            ## build splice graph

            sg = Splice_graph()
            
            contig_strand_token = "{}^{}".format(contig_acc, contig_strand)
            input_transcripts = contig_strand_to_input_transcripts[contig_strand_token]
            logger.info("Have {} transcripts on {}".format(len(input_transcripts), contig_strand_token))
            
            if input_transcripts is not None and len(input_transcripts) == 0:
                input_transcripts = None


            if QUANT_ONLY:

                # get path assignments for the input transcripts
                # get the path assignments for the reads.
                # compare read mappings, assign categories

                # if no transcripts for this contig/strand, nothing to quant on
                if input_transcripts is None:
                    logger.info(f"-no isoforms to quant on {contig_acc} [{contig_strand}]")
                    continue

                # for quant only, build sg only based on the input gtf and not the alignments in the bam
                sg.build_splice_graph_for_contig(contig_acc, contig_strand, contig_seq_str,
                                                 bam_file_for_sg,
                                                 restrict_region_lend, restrict_region_rend, input_transcripts, QUANT_ONLY)

                if sg.is_empty():
                    logger.info(f"-no splice graph created for contig: {contig_acc}.... skipping.")
                    continue

                if PASA_SALRAA_Globals.DEBUG:
                    sg.write_intron_exon_splice_graph_bed_files("{}/__prereconstruct.{}.{}.pad1".format(prereconstruct_info_dir, contig_acc, contig_strand), pad=1)

                

                pasa_salraa_obj = PASA_SALRAA(sg, CPU)
                logger.debug("\n//SECTION QUANT: Assigning input transcript paths in graph")
                pasa_salraa_obj.assign_transcripts_paths_in_graph(input_transcripts)

                if PASA_SALRAA_Globals.DEBUG:
                    report_transcript_paths_in_graph(input_transcripts, "__input_transcripts_path_in_graph")

                    
                
                logger.debug("\n//SECTION QUANT: Assigning reads to paths in graph.")
                mp_counter = pasa_salraa_obj._populate_read_multi_paths(contig_acc, contig_strand, contig_seq_str, bam_file_for_quant, allow_spacers)

                q = Quantify()
                logger.debug("\n//SECTION QUANT: Quantifying transcripts according to read support.")
                read_name_to_fractional_transcript_assignment = q.quantify(sg, input_transcripts, mp_counter, run_EM)
                q.report_quant_results(input_transcripts, read_name_to_fractional_transcript_assignment, ofh, ofh_quant_read_tracker)


            else:
                ##---------------------
                ## Assemble transcripts

                sg.build_splice_graph_for_contig(contig_acc, contig_strand, contig_seq_str,
                                                 bam_file_for_sg,
                                                 restrict_region_lend, restrict_region_rend, input_transcripts, QUANT_ONLY)

                if sg.is_empty():
                    logger.info(f"-no splice graph created for contig: {contig_acc}.... skipping.")
                    continue

                if PASA_SALRAA_Globals.DEBUG:
                    sg.write_intron_exon_splice_graph_bed_files("{}/__prereconstruct.{}.{}.pad1".format(prereconstruct_info_dir, contig_acc, contig_strand), pad=1)


                pasa_salraa_obj = PASA_SALRAA(sg, CPU)
                logger.info(f"-building splice graph for {contig_acc}")
                pasa_salraa_obj.build_multipath_graph(contig_acc, contig_strand, contig_seq_str, bam_file_for_sg, allow_spacers)

                if input_transcripts and PASA_SALRAA_Globals.DEBUG:
                    pasa_salraa_obj.assign_transcripts_paths_in_graph(input_transcripts)
                    report_transcript_paths_in_graph(input_transcripts, "__input_transcripts_path_in_graph")
                
                logger.info(f"-begin reconstructing isoforms for {contig_acc}")
                transcripts = pasa_salraa_obj.reconstruct_isoforms(single_best_only)


                transcripts, frac_read_assignments = Quantify.prune_likely_degradation_products(transcripts, sg, run_EM)
                
                if PASA_SALRAA_Globals.DEBUG or args.include_asm_draft_quant:
                    prefilter_transcripts_ofh = open("__transcripts-prefilter.gtf", "at")
                    for transcript in transcripts:
                        prefilter_transcripts_ofh.write(transcript.to_GTF_format() + "\n")
                    prefilter_transcripts_ofh.close()
                    
                    debug_quant_ofh = open("__transcripts-prefilter-quant_info.tsv", "at")
                    debug_quant_read_tracking_ofh = open("__transcripts-prefilter-quant_info.reads_tracked.tsv", "at")
                    q = Quantify()
                    q.report_quant_results(transcripts, frac_read_assignments, debug_quant_ofh, debug_quant_read_tracking_ofh)
                    debug_quant_ofh.close()
                    debug_quant_read_tracking_ofh.close()

                
                if min_isoform_fraction > 0:
                    transcripts, frac_read_assignments = Quantify.filter_isoforms_by_min_isoform_fraction(transcripts, min_isoform_fraction, run_EM)

                logger.info("writing gtf output for {} [{}] containing {} transcripts".format(contig_acc, contig_strand, len(transcripts)))

                if PASA_SALRAA_Globals.DEBUG:
                    report_transcript_paths_in_graph(transcripts, "__output_transcripts_path_in_graph")
                    
                for transcript in transcripts:
                    ofh.write(transcript.to_GTF_format() + "\n")

                if PASA_SALRAA_Globals.DEBUG or args.include_asm_draft_quant:
                    debug_quant_ofh = open("__quant_info.tsv", "at")
                    debug_quant_read_tracking_ofh = open("__quant_info.reads_tracked.tsv", "at")
                    q = Quantify()
                    q.report_quant_results(transcripts, frac_read_assignments, debug_quant_ofh, debug_quant_read_tracking_ofh)
                    debug_quant_ofh.close()
                    debug_quant_read_tracking_ofh.close()

                    
    ofh.close()
    if QUANT_ONLY:
        ofh_quant_read_tracker.close()

    
    return
    

def get_genome_contigs_listing(genome_fasta_filename):

    fai_file = "{}.fai".format(genome_fasta_filename)
    if not os.path.exists(fai_file):
        subprocess.check_call("samtools faidx {}".format(genome_fasta_filename),
                              shell=True)

    contigs_list = list()
    
    with open(fai_file) as fh:
        for line in fh:
            vals = line.split("\t")
            contig_acc = vals[0]
            contigs_list.append(contig_acc)

    return contigs_list


def report_transcript_paths_in_graph(transcripts, filename):

    with open(filename, "at") as ofh:
        for transcript in transcripts:
            sp = transcript.get_simple_path()
            exon_segments = transcript.get_exon_segments()
            transcript_id = transcript.get_transcript_id()
            print("\t".join([transcript_id, str(exon_segments), str(sp)]), file=ofh)

    return
    
            
if __name__ == '__main__':
    main()
